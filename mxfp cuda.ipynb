{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lb/miniconda3/envs/mxbfp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from mx import mx_mapping, finalize_mx_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing and loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, device):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_loss = float('inf')\n",
    "    best_model_path = 'best_model.pth'\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        epoch_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device) \n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} done. Loss: {epoch_loss}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    return best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_average(model, test_loader, device, num_evaluations=10):\n",
    "    total_accuracy = 0\n",
    "    total_time = 0\n",
    "    for _ in range(num_evaluations):\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        inference_time = time.time() - start_time\n",
    "\n",
    "        total_accuracy += accuracy\n",
    "        total_time += inference_time\n",
    "\n",
    "    average_accuracy = total_accuracy / num_evaluations\n",
    "    average_time = total_time / num_evaluations\n",
    "    return average_accuracy, average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done. Loss: 1.3176605977365732\n",
      "Epoch 2 done. Loss: 0.9313664588019671\n",
      "Epoch 3 done. Loss: 0.7648372553346102\n",
      "Epoch 4 done. Loss: 0.6300224576078718\n",
      "Epoch 5 done. Loss: 0.5067216605900804\n",
      "Epoch 6 done. Loss: 0.3874464797051361\n",
      "Epoch 7 done. Loss: 0.2889585506904613\n",
      "Epoch 8 done. Loss: 0.20265076383757774\n",
      "Epoch 9 done. Loss: 0.14291796909021143\n",
      "Epoch 10 done. Loss: 0.11030141576586286\n"
     ]
    }
   ],
   "source": [
    "# Train the model in FP32\n",
    "model_fp32 = SimpleCNN().to(device)\n",
    "best_model_path = train(model_fp32, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 - Average Accuracy: 71.86%, Average Inference Time: 2.2540157556533815 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate in FP32\n",
    "average_accuracy_fp32, average_time_fp32 = evaluate_average(model_fp32, test_loader, device)\n",
    "print(f\"FP32 - Average Accuracy: {average_accuracy_fp32}%, Average Inference Time: {average_time_fp32} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MXFP4\n",
    "mx_specs = {\n",
    "    'w_elem_format': 'fp4_e2m1',\n",
    "    'a_elem_format': 'fp4_e2m1',\n",
    "    'w_elem_format_bp':'fp4_e2m1',\n",
    "    'a_elem_format_bp_ex':'fp4_e2m1',\n",
    "    'a_elem_format_bp_os': 'int8',\n",
    "    'scale_bits': 8,\n",
    "    'block_size': 32,\n",
    "    'custom_cuda': True,\n",
    "    'bfloat': 16,\n",
    "    'quantize_backprop': True\n",
    "}\n",
    "\n",
    "mx_specs = finalize_mx_specs(mx_specs)\n",
    "mx_mapping.inject_pyt_ops(mx_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done. Loss: 1.3548200424674832\n",
      "Epoch 2 done. Loss: 0.9949734219352303\n",
      "Epoch 3 done. Loss: 0.8371523920913486\n",
      "Epoch 4 done. Loss: 0.7198510145592263\n",
      "Epoch 5 done. Loss: 0.607438024390689\n",
      "Epoch 6 done. Loss: 0.5043549986408494\n",
      "Epoch 7 done. Loss: 0.4094330814221631\n",
      "Epoch 8 done. Loss: 0.31546328812265945\n",
      "Epoch 9 done. Loss: 0.2577301764198581\n",
      "Epoch 10 done. Loss: 0.20743465050578574\n",
      "Epoch 11 done. Loss: 0.17977961066805417\n",
      "Epoch 12 done. Loss: 0.14907906397872264\n",
      "Epoch 13 done. Loss: 0.13879902921545575\n",
      "Epoch 14 done. Loss: 0.1274116559351897\n",
      "Epoch 15 done. Loss: 0.11853514945306018\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and cast to FP4\n",
    "model_mxfp4 = SimpleCNN().to(device)\n",
    "# model_mxfp4.load_state_dict(torch.load(best_model_path))\n",
    "best_model_mxfp4_model_path = train(model_mxfp4, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mxfp4.load_state_dict(torch.load(best_model_mxfp4_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MXFP4 - Average Accuracy: 68.33000000000001%, Average Inference Time: 2.59999737739563 seconds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate in FP4\n",
    "average_accuracy_mxfp4, average_time_mxfp4 = evaluate_average(model_mxfp4, test_loader, device)\n",
    "print(f\"MXFP4 - Average Accuracy: {average_accuracy_mxfp4}%, Average Inference Time: {average_time_mxfp4} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxbfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
